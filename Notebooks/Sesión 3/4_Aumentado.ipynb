{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gabrielcarcedo/Programa-Intensivo-en-Ciencia-de-Datos-De-los-Fundamentos-al-Deep-Learning/blob/main/Notebooks/Sesi%C3%B3n%203/4_Aumentado.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Módulo 4: Redes neuronales artificiales\n",
        "## Tema: Redes neuronales convolucionales\n",
        "\n",
        "\n",
        "El objetivo de esta libreta es utilizar las dos técnicas más comunes de aumentado de datos, que son: transformaciones geométricas y transformación de color.\n",
        "\n",
        "La imagen usada en esta libreta fue descargada del sitio: [Stanford Dogs Dataset](http://vision.stanford.edu/aditya86/ImageNetDogs/main.html)\n"
      ],
      "metadata": {
        "id": "AvK4ux8sXno7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DY93hWHLwoMN"
      },
      "outputs": [],
      "source": [
        "#Carga de bibliotecas\n",
        "import skimage.io as skio\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from scipy import misc\n",
        "from PIL import Image\n",
        "from skimage.color import rgb2gray\n",
        "import torch\n",
        "import torchvision.transforms as transforms"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Montaje de Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "ruta_imagen = \"/content/drive/MyDrive/Colab Notebooks/2025_TallerIIMAS/n02099601_1743.jpg\""
      ],
      "metadata": {
        "id": "IWrL8wmDxBn7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Paso 1: Carga de imagen"
      ],
      "metadata": {
        "id": "WqxnAySWX8lT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ver_imagen(imagen):\n",
        "  #Función para ver la imagen generada\n",
        "  plt.figure(figsize=(15,15))\n",
        "  plt.imshow(imagen)\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "nS-6MEAyL8YJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imagen = skio.imread(ruta_imagen)\n",
        "print(\"Tamaño de la imagen: \", imagen.shape)"
      ],
      "metadata": {
        "id": "jdmj9WRVMhmJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ver_imagen(imagen) #Visualizando la imagen cargada"
      ],
      "metadata": {
        "id": "0s5LM7MiMDj9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Paso 2: transformaciones geométricas"
      ],
      "metadata": {
        "id": "38bsdclcSNIl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Ajustar el tamaño de la imagen a un nuevo tamaño\n",
        "resize_ = transforms.Compose([transforms.ToPILImage(), #Esta transformación usa PIL\n",
        "                              transforms.Resize(size=(150,250))])\n",
        "imagen_resize = resize_(imagen)\n",
        "ver_imagen(imagen_resize)"
      ],
      "metadata": {
        "id": "HkfQRR76MMv1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Transformación horizontal\n",
        "horizontal = transforms.Compose([transforms.ToPILImage(),\n",
        "                                 transforms.RandomHorizontalFlip(p=1)])\n",
        "imagen_horizontal = horizontal(imagen)\n",
        "ver_imagen(imagen_horizontal)"
      ],
      "metadata": {
        "id": "CoL0zDnhM43X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Transformación vertical\n",
        "vertical = transforms.Compose([transforms.ToPILImage(),\n",
        "                               transforms.RandomVerticalFlip(p=1)])\n",
        "imagen_vertical = vertical(imagen)\n",
        "ver_imagen(imagen_vertical)"
      ],
      "metadata": {
        "id": "yL7-YauBR7oV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Rotar\n",
        "rotar = transforms.Compose([transforms.ToPILImage(),\n",
        "                            transforms.RandomRotation(degrees=66)])\n",
        "imagen_rotar = rotar(imagen)\n",
        "ver_imagen(imagen_rotar)"
      ],
      "metadata": {
        "id": "2YLrKtEBXHxL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transformaciones de color"
      ],
      "metadata": {
        "id": "fdfYNODdS65H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "brillo = transforms.Compose([transforms.ToPILImage(),\n",
        "                             transforms.ColorJitter(brightness=(0.1,0.6),\n",
        "                             contrast=1,\n",
        "                             saturation=0, hue=0.4)])\n",
        "imagen_brillo = brillo(imagen)\n",
        "ver_imagen(imagen_brillo)"
      ],
      "metadata": {
        "id": "eH3TYZPkTAJg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cropping = transforms.Compose([transforms.ToPILImage(),\n",
        "                               transforms.RandomCrop(size=(224,312))])\n",
        "\n",
        "imagen_cropping = cropping(imagen)\n",
        "ver_imagen(imagen_cropping)"
      ],
      "metadata": {
        "id": "UGJOE1XZTXSk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Para mayor información, consulta:\n",
        "\n",
        "* [Illustration of transforms](https://pytorch.org/vision/main/auto_examples/transforms/plot_transforms_illustrations.html#sphx-glr-auto-examples-transforms-plot-transforms-illustrations-py)\n",
        "\n"
      ],
      "metadata": {
        "id": "ZaHpDdZxXURb"
      }
    }
  ]
}